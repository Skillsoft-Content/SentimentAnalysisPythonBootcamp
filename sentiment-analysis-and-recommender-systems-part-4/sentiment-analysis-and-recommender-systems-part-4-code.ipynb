{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## SENTIMENT ANALYSIS AND RECOMMENDER SYSTEMS PART 4/SENTIMENT ANALYSIS AND RECOMMENDER SYSTEMS PART 4 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf21a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 9: Loading the packages  ####\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10470bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Loading the packages  ####\n",
    "\n",
    "from math import sqrt\n",
    "from scipy.sparse.linalg import svds\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f05a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: Directory settings  ####\n",
    "\n",
    "# Set 'main_dir' to location of the project folder\n",
    "from pathlib import Path\n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04012a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 12: Load the subset of data  ####\n",
    "\n",
    "# Read in the datasets.\n",
    "rating_subset = pd.read_csv(data_dir+'/ratings-subset.csv')\n",
    "movies_subset = pd.read_csv(data_dir+'/movies-subset.csv')\n",
    "# Select only movie ID and title from movies dataset.\n",
    "movies_subset = movies_subset[['movieId', 'title']]\n",
    "# Merge both ratings and movies dataframes.\n",
    "rating_df = pd.merge(movies_subset, rating_subset)\n",
    "# View the summary and head of the merged dataframe.\n",
    "print(rating_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0275ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Item-based recommender implementation  ####\n",
    "\n",
    "userRating = rating_df.pivot_table(index = ['userId'],\n",
    "                                   columns = ['title'], values = 'rating')\n",
    "                                    \n",
    "print(userRating.head())     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 14: Item correlation matrix  ####\n",
    "\n",
    "# corrMatrix = userRating.corr(method = 'pearson', min_periods = 100)\n",
    "# corrMatrix.to_csv('corrMatrix.csv', index = True, encoding = 'utf-8')\n",
    "corrMatrix = pd.read_csv(data_dir+ '/corrMatrix.csv')\n",
    "print(corrMatrix.head())\n",
    "\n",
    "corrMatrix = corrMatrix.set_index('title')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d218bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 16: Suggest movies to user  ####\n",
    "\n",
    "user_corr = pd.Series()\n",
    "\n",
    "user_id = 25\n",
    "\n",
    "# Create a list of all films with all correlations multiplied by the rating.\n",
    "for film in userRating.iloc[user_id].dropna().index:\n",
    "    corr_list = corrMatrix[film].dropna() * userRating.iloc[user_id][film]\n",
    "    user_corr = user_corr.append(corr_list)\n",
    "\n",
    "# Group by movie ID and sum the ratings to remove duplicates.\n",
    "user_corr = user_corr.groupby(user_corr.index).sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 17: Suggest movies to user  ####\n",
    "\n",
    "# Create a list of movies the user has already seen and remove them.\n",
    "title_list = []\n",
    "\n",
    "for i in range(len(userRating.iloc[user_id].dropna().index)):\n",
    "    if userRating.iloc[user_id].dropna().index[i] in user_corr:\n",
    "        title_list.append(userRating.iloc[user_id].dropna().index[i])\n",
    "    else:\n",
    "        pass\n",
    "user_corr = user_corr.drop(title_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d649778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 18: Suggest movies to user  ####\n",
    "\n",
    "print('Hi! Based on the films that you have seen, you might like: \\n')\n",
    "for i in userRating.iloc[user_id].dropna().index:\n",
    "    print(i)\n",
    "# Suggest the top 10 movies.\n",
    "print('\\n I would suggest that you watch: \\n')\n",
    "\n",
    "for i in user_corr.sort_values(ascending = False).index[:10]:\n",
    "    print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 27: Find total users and movies  ####\n",
    "\n",
    "# Reading the ratings file.\n",
    "ratings = pd.read_csv(data_dir+ '/ratings.csv', sep='\\t', encoding='latin-1', \n",
    "usecols = ['user_id', 'movie_id', 'rating'])\n",
    "# Find total number of unique users and movies.\n",
    "n_users = ratings.user_id.unique().shape[0]\n",
    "n_movies = ratings.movie_id.unique().shape[0]\n",
    "print('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_movies))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 28: Data preparation for SVD  ####\n",
    "\n",
    "Ratings = ratings.pivot(index = 'user_id',columns = 'movie_id', \n",
    "values = 'rating').fillna(0)\n",
    "\n",
    "print(Ratings.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 29: De-normalize the data and check the amount of sparsity  ####\n",
    "\n",
    "# Normalize the data.\n",
    "R = Ratings.to_numpy()\n",
    "\n",
    "user_ratings_mean = np.mean(R, axis = 1)\n",
    "Ratings_demeaned = R - user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "# Check the percentage of sparsity.\n",
    "sparsity = round(1.0 - len(ratings) / float(n_users * n_movies), 3)\n",
    "print('The sparsity level of MovieLens1M dataset is ' +  str(sparsity * 100) + '%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 30: SVD implementation  ####\n",
    "\n",
    "U, sigma, Vt = svds(Ratings_demeaned, k = 50)\n",
    "\n",
    "# Convert the sigma matrix to the diagonal matrix form.\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 31: SVD implementation  ####\n",
    "\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 32: SVD implementation  ####\n",
    "\n",
    "preds = pd.DataFrame(all_user_predicted_ratings, columns = Ratings.columns)\n",
    "print(preds.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14000a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 33: SVD implementation  ####\n",
    "\n",
    "def recommend_movies(predictions, userID, movies, original_ratings, num_recommendations):\n",
    "    user_row_number = userID - 1 # User ID starts at 1, not 0\n",
    "    sorted_user_predictions = preds.iloc[user_row_number].sort_values(ascending = False) # User ID starts at 1\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    user_data = original_ratings[original_ratings.user_id == (userID)]\n",
    "    user_full = (user_data.merge(movies, how = 'left', left_on = 'movie_id', right_on = 'movie_id').sort_values(['rating'], ascending=False))\n",
    "    print('User {0} has already rated {1} movies.'.format(userID, user_full.shape[0]))\n",
    "    print('Recommending highest {0} predicted ratings movies not already     rated.'.format(num_recommendations))\n",
    "    # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "    recommendations = (movies[~movies['movie_id'].isin(user_full['movie_id'])].\n",
    "         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',\n",
    "               left_on = 'movie_id',right_on = 'movie_id').\n",
    "         rename(columns = {user_row_number: 'Predictions'}).\n",
    "         sort_values('Predictions', ascending = False).iloc[:num_recommendations, :-1])\n",
    "    return user_full, recommendations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b44e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Recommend movies using SVD  ####\n",
    "\n",
    "# Reading movies file.\n",
    "movies = pd.read_csv(data_dir+ '/movies.csv', sep='\\t', encoding='latin-1', \n",
    "usecols = ['movie_id', 'title', 'genres'])\n",
    "already_rated, predictions = recommend_movies(preds, 1310, movies, ratings, 20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 35: Recommend movies using SVD  ####\n",
    "\n",
    "# Top 20 movies that User 1310 has rated. \n",
    "print(already_rated[['user_id', 'title']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 36: Recommend movies using SVD  ####\n",
    "\n",
    "# Top 20 movies that User 1310 hopefully will enjoy.\n",
    "print(predictions[['movie_id', 'title']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 40: Model evaluation  ####\n",
    "\n",
    "# Load Reader library.\n",
    "reader = Reader()\n",
    "\n",
    "# Load ratings dataset with the Dataset library.\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41324d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 41: Model evaluation: compute RMSE  ####\n",
    "\n",
    "# Use the SVD algorithm.\n",
    "svd = SVD()\n",
    "# Compute the RMSE of the SVD algorithm.\n",
    "evaluate_model = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2918802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 42: Model evaluation: fitting the model  ####\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d896ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 43: Model evaluation: prediction  ####\n",
    "\n",
    "# User 1310 and his prior ratings.\n",
    "ratings[ratings['user_id'] == 1310].head() \n",
    "# Average rating user 1310 will give to movie ID 1994.\n",
    "svd.predict(1310, 1994)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
