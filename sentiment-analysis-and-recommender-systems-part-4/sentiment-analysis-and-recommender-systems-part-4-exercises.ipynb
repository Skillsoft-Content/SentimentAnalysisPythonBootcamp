{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis and Recommender Systems Part 4 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 \n",
    "##### Load libraries that are used in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 \n",
    "##### Set working directory to folder where the dataset is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Read in 'lastfm_ratings.csv' dataset to a dataframe named 'fm_ratings' and 'lastfm_artists.csv' as 'fm_artists'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Transform the fm_ratings with userID as the row and artist_name as the column and the rating as the value. Set it as `userRating`.\n",
    "##### Find the correlation matrix for the artist_name. Do not use min_periods as we did in module, since our dataset is small here.\n",
    "##### It could take a lot of time to form the correlation matrix, so you can also load from our data_dir where we already have it calculated and saved.\n",
    "##### Load `corrMatrix_ex.csv` as corrMatrix - also, set the first column `artist_name` as the index for the dataframe."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hint: df = df.set_index('artist_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### We will find recommendations for userID 25. Assign user_id as 25 and use the same steps we did in the module to find the artist recommendation.\n",
    "##### First, create a list of all artists with all correlations multiplied by rating.\n",
    "##### Group by artist_id and sum the ratings to remove the duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Find the list of artists that the user has already heard and remove them.\n",
    "##### Give top 10 recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Find the total number of users and artists.\n",
    "##### Transform our fm_ratings dataset using pivot_table where we have 1 row per user and 1 column per artist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Convert the pivot table into matrix and find the sparsity percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Fetch the first 50 latent features and return the list of artists the user has already rated.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### The following function has been modified from the function we used in the module to recommend artists.\n",
    "##### Use this function and predict 20 new artists to user with ID 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(predictions, user, artists, original_ratings, num_recommendations):\n",
    "    \n",
    "    # Get and sort the user's predictions.\n",
    "    user_row_number = user - 1 # User ID starts at 1, not 0\n",
    "    sorted_user_predictions = preds.iloc[user_row_number].sort_values(ascending=False) # User ID starts at 1\n",
    "    \n",
    "    # Get the user's data and merge in the artist information.\n",
    "    user_data = original_ratings[original_ratings.userID == (user)]\n",
    "    user_full = (user_data.merge(fm_artists, how = 'left', left_on = 'artistID', right_on = 'artistID').\n",
    "                     sort_values(['rating'], ascending=False)\n",
    "                 )\n",
    "\n",
    "    print('User {0} has already rated {1} artists.'.format(user, user_full.shape[0]))\n",
    "    print('Recommending highest {0} predicted rating artists not already rated.'.format(num_recommendations))\n",
    "    \n",
    "    # Recommend the highest predicted rating artists that the user hasn't listened yet.\n",
    "    recommendations = (fm_artists[~fm_artists['artistID'].isin(user_full['artistID'])].\n",
    "         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',\n",
    "               left_on = 'artistID',\n",
    "               right_on = 'artistID').\n",
    "         rename(columns = {user_row_number: 'Predictions'}).\n",
    "         sort_values('Predictions', ascending = False).\n",
    "                       iloc[:num_recommendations, :-1]\n",
    "                      )\n",
    "\n",
    "    return user_full, recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Load the reader library and load the dataset `fm_ratings` to reader.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Build the SVD algorithm and evaluate with our data using RMSE metric with cross validation set to 5.\n",
    "##### What are the RMSE values?\n",
    "##### Train the dataset and fit it.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Using our algorithm, predict what would be the rating given by user 1200 to artist ID 400.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af1c2328f5544355579310f76569f81b262cdac47b296e1f8c8cfd250fec34f9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
