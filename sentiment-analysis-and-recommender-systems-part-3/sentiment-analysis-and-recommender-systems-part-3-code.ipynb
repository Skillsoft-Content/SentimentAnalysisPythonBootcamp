{"cells":[{"cell_type":"code","execution_count":null,"id":"59ba68e5","metadata":{"id":"59ba68e5"},"outputs":[],"source":["#######################################################\n","#######################################################\n","############    COPYRIGHT - DATA SOCIETY   ############\n","#######################################################\n","#######################################################\n","\n","## SENTIMENT ANALYSIS AND RECOMMENDER SYSTEMS PART 3/SENTIMENT ANALYSIS AND RECOMMENDER SYSTEMS PART 3 ##\n","\n","## NOTE: To run individual pieces of code, select the line of code and\n","##       press ctrl + enter for PCs or command + enter for Macs\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"58ee0c78","metadata":{"id":"58ee0c78"},"outputs":[],"source":["#=================================================-\n","#### Slide 9: Loading the packages  ####\n","\n","import os\n","import pickle\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import wordcloud\n","from wordcloud import WordCloud, STOPWORDS\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics.pairwise import pairwise_distances\n","from sklearn.metrics import mean_squared_error\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"acfb38a1","metadata":{"id":"acfb38a1"},"outputs":[],"source":["#=================================================-\n","#### Slide 10: Loading the packages  ####\n","\n","from math import sqrt\n","from scipy.sparse.linalg import svds\n","from surprise import Reader\n","from surprise import Dataset\n","from surprise import SVD\n","from surprise.model_selection import cross_validate\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e4e37c22","metadata":{"id":"e4e37c22"},"outputs":[],"source":["#=================================================-\n","#### Slide 11: Directory settings  ####\n","\n","# Set 'main_dir' to location of the project folder\n","from pathlib import Path\n","home_dir = Path(\".\").resolve()\n","main_dir = home_dir.parent\n","data_dir = str(main_dir) + \"/data\"\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"af7da4a6","metadata":{"id":"af7da4a6"},"outputs":[],"source":["#=================================================-\n","#### Slide 12: Load the dataset and check the structure  ####\n","\n","# Reading the ratings file.\n","ratings = pd.read_csv(data_dir+ '/ratings.csv', sep='\\t', encoding='latin-1', \n","usecols = ['user_id', 'movie_id', 'rating'])\n","# Reading users file.\n","users = pd.read_csv(data_dir+ '/users.csv', sep='\\t', encoding='latin-1', \n","usecols = ['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n","# Reading movies file.\n","movies = pd.read_csv(data_dir+ '/movies.csv', sep='\\t', encoding='latin-1', \n","usecols = ['movie_id', 'title', 'genres'])\n","print(ratings.info())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6e6a8fb8","metadata":{"id":"6e6a8fb8"},"outputs":[],"source":["#=================================================-\n","#### Slide 13: Load the dataset and check the structure  ####\n","\n","print(users.info())\n","print(movies.info())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"fe2207f6","metadata":{"id":"fe2207f6"},"outputs":[],"source":["#=================================================-\n","#### Slide 14: View the head of the dataset  ####\n","\n","print(ratings.head(3))\n","\n","print(users.head(3))\n","\n","print(movies.head(3))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"96cb15dc","metadata":{"id":"96cb15dc"},"outputs":[],"source":["#=================================================-\n","#### Slide 15: Movies - data exploration  ####\n","\n","# Create a word cloud of the movie titles.\n","movies['title'] = movies['title'].fillna(\"\").astype('str')\n","title_corpus = ' '.join(movies['title'])\n","title_wordcloud = WordCloud(stopwords = STOPWORDS, background_color = 'black', \n","height = 2000, width = 4000).generate(title_corpus)\n","\n","# Plot the word cloud.\n","plt.figure(figsize = (16, 8))\n","plt.imshow(title_wordcloud)\n","plt.axis('off')\n","plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"9a3d5564","metadata":{"id":"9a3d5564"},"outputs":[],"source":["#=================================================-\n","#### Slide 16: Ratings - data exploration  ####\n","\n","# Get summary statistics of ratings.\n","print(ratings['rating'].describe())\n","sns.set_style('whitegrid')\n","sns.set(font_scale=1.5)\n","\n","# Display distribution of ratings.\n","sns.countplot(ratings['rating'])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"1ce4afc4","metadata":{"id":"1ce4afc4"},"outputs":[],"source":["#=================================================-\n","#### Slide 17: Combining dataframes  ####\n","\n","# Join all 3 files into one dataframe.\n","dataset = pd.merge(pd.merge(movies, ratings), users)\n","\n","# Display 5 movies with highest ratings.\n","print(dataset[['title', 'genres', 'rating']].sort_values('rating', ascending = False).head(5))\n","# Make a census of the genre keywords.\n","genre_labels = set()\n","for s in movies['genres'].str.split('|').values:\n","    genre_labels = genre_labels.union(set(s))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"56c07b9f","metadata":{"id":"56c07b9f"},"outputs":[],"source":["#=================================================-\n","#### Slide 18: Function to count the genres  ####\n","\n","# Create a function that counts the number of times each of the genre keywords appear.\n","def count_word(dataset, ref_col, census):\n","    keyword_count = dict()\n","    for s in census: \n","        keyword_count[s] = 0\n","    for census_keywords in dataset[ref_col].str.split('|'):        \n","        if type(census_keywords) == float and pd.isnull(census_keywords): \n","            continue        \n","        for s in [s for s in census_keywords if s in census]: \n","            if pd.notnull(s): \n","                keyword_count[s] += 1\n","    # Convert the dictionary in a list to sort the keywords by frequency.\n","    keyword_occurrences = []\n","    for k,v in keyword_count.items():\n","        keyword_occurrences.append([k,v])\n","    keyword_occurrences.sort(key = lambda x:x[1], reverse = True)\n","    return keyword_occurrences, keyword_count\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b0742227","metadata":{"id":"b0742227"},"outputs":[],"source":["#=================================================-\n","#### Slide 19: Function to count the genres  ####\n","\n","# Calling this function gives access to a list of genre keywords, which are sorted by decreasing frequency.\n","keyword_occurrences, dum = count_word(movies, 'genres', genre_labels)\n","print(keyword_occurrences[:5])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"be5de502","metadata":{"id":"be5de502"},"outputs":[],"source":["#=================================================-\n","#### Slide 21: Exercise 1  ####\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3232ef4f","metadata":{"id":"3232ef4f"},"outputs":[],"source":["#=================================================-\n","#### Slide 29: Content-based recommender implementation  ####\n","\n","# Break up the big genre string into a string array.\n","movies['genres'] = movies['genres'].str.split('|')\n","\n","# Convert genres to string values.\n","movies['genres'] = movies['genres'].fillna(\"\").astype('str')\n","print(movies['genres'].head())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"150eb1df","metadata":{"id":"150eb1df"},"outputs":[],"source":["#=================================================-\n","#### Slide 30: Content-based recommender implementation - cont'd  ####\n","\n","tf = TfidfVectorizer(analyzer = 'word',\n","ngram_range = (1, 2),\n","min_df = 0, \n","stop_words = 'english')\n","\n","tfidf_matrix = tf.fit_transform(movies['genres'])\n","print(tfidf_matrix.shape)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"be23339c","metadata":{"id":"be23339c"},"outputs":[],"source":["#=================================================-\n","#### Slide 31: Content-based recommender implementation - cont'd  ####\n","\n","# Cosine similarity for all movies, and look at the first four rows and columns.\n","cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n","print(cosine_sim[:4, :4])\n","\n","print(cosine_sim.shape)\n","# Build a 1-dimensional array with movie titles.\n","titles = movies['title']\n","indices = pd.Series(movies.index, index = movies['title'])\n","print(titles[0:5])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c421f4b6","metadata":{"id":"c421f4b6"},"outputs":[],"source":["#=================================================-\n","#### Slide 32: Content-based recommender implementation - cont'd  ####\n","\n","# Function that get movie recommendations based on the cosine similarity score of movie genres.\n","def genre_recommendations(title):\n","    idx = indices[title]\n","    sim_scores = list(enumerate(cosine_sim[idx]))\n","    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","    sim_scores = sim_scores[1:21]\n","    movie_indices = [i[0] for i in sim_scores]\n","    return titles.iloc[movie_indices]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4d052684","metadata":{"id":"4d052684"},"outputs":[],"source":["#=================================================-\n","#### Slide 33: Content based recommender implementation - cont'd  ####\n","\n","print(genre_recommendations('Toy Story (1995)').head(20))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5b117f63","metadata":{"id":"5b117f63"},"outputs":[],"source":["#=================================================-\n","#### Slide 35: Generate content-based recommendation  ####\n","\n","print(genre_recommendations('Assassins (1995)').head(20))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"d284bd5c","metadata":{"id":"d284bd5c"},"outputs":[],"source":["#=================================================-\n","#### Slide 36: Generate content-based recommendation  ####\n","\n","print(genre_recommendations('Sense and Sensibility (1995)').head(20))\n","\n","\n"]}],"metadata":{"language":"python","colab":{"name":"sentiment-analysis-and-recommender-systems-part-3-code.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}